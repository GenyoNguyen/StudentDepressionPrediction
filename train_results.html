<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Training and Results - Student Depression Prediction" />
  <meta name="keywords" content="model training, results, evaluation, machine learning, depression prediction" />
  <meta name="author" content="Your Name" />
  <title>Models & Results - Student Depression Prediction</title>
  <link rel="icon" href="static/assets/logo.svg" type="image/svg+xml">
  <link rel="stylesheet" href="css/styles.css" />
  <style>
    .chart-analysis {
      margin-top: 15px;
      padding: 10px;
      font-size: 0.95em;
      line-height: 1.5;
      color: var(--text-color);
    }

    .results-section img {
      max-width: 100%;
      height: auto;
      margin-bottom: 1.5rem;
      border-radius: 8px;
      border: 1px solid rgba(128, 128, 128, 0.1);
    }

    .model-report {
      background: rgba(128, 128, 128, 0.05);
      border-radius: 12px;
      padding: 1.5rem;
      margin-bottom: 2rem;
      border: 1px solid rgba(128, 128, 128, 0.1);
      width: 100%;
      max-width: unset;
      box-sizing: border-box;
      grid-column: 1 / -1;
    }

    .model-metrics {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      margin-top: 1rem;
    }

    .metric-card {
      background: var(--header-bg);
      padding: 1rem;
      border-radius: 8px;
      text-align: center;
    }

    .metric-value {
      font-size: 1.5rem;
      font-weight: bold;
      color: var(--accent-color);
    }

    .visualization-group {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin: 1rem 0;
    }

    .visualization-group>div {
      background: var(--header-bg);
      padding: 1rem;
      border-radius: 8px;
      border: 1px solid rgba(128, 128, 128, 0.1);
    }

    .visualization-group img {
      width: 100%;
      height: auto;
      margin: 1rem 0;
    }

    .visualization-group h5 {
      margin: 0;
      color: var(--text-color);
    }

    .model-metrics-group {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin-bottom: 1.5rem;
    }

    .model-metrics-group h5 {
      text-align: center;
      margin-bottom: 0.5rem;
      font-size: 1.1em;
      color: var(--text-color);
    }


    .model-metrics-group img {
      background-color: #ffffff;
    }

    .classification-report {
      background: var(--header-bg);
      padding: 1rem;
      border-radius: 8px;
      white-space: pre-wrap;
      font-family: monospace;
      overflow-x: auto;
      font-size: 1.2rem;
      text-align: center;
    }

    .model-comparison-table {
      margin: 2rem 0;
      overflow-x: auto;
    }

    .model-comparison-table table {
      width: 100%;
      border-collapse: collapse;
      text-align: center;
    }

    .model-comparison-table th {
      background-color: var(--accent-color);
      padding: 0.8rem;
      border: 1px solid rgba(255, 255, 255, 0.2);
    }

    .model-comparison-table td {
      padding: 0.8rem;
      border: 1px solid rgba(128, 128, 128, 0.2);
    }

    .model-comparison-table tr:nth-child(even) {
      background-color: rgba(128, 128, 128, 0.05);
    }

    .model-comparison-table tr:hover {
      background-color: rgba(128, 128, 128, 0.1);
    }

    /* Sidebar Navigation */
    .sidebar {
      position: fixed;
      top: 0;
      left: -280px;
      width: 280px;
      height: 100vh;
      background: var(--header-bg);
      box-shadow: 2px 0 8px var(--header-shadow);
      transition: left 0.3s ease;
      z-index: 1000;
      padding: 1rem;
    }

    .sidebar.active {
      left: 0;
    }

    .sidebar-nav {
      margin-top: 4rem;
    }

    .sidebar-nav ul {
      list-style: none;
      padding: 0;
    }

    .sidebar-nav ul li {
      margin-bottom: 1rem;
    }

    .sidebar-nav ul li a {
      color: var(--text-color);
      text-decoration: none;
      font-size: 1.1rem;
      display: block;
      padding: 0.8rem 1rem;
      border-radius: 8px;
      transition: background 0.2s;
    }

    .sidebar-nav ul li a:hover,
    .sidebar-nav ul li a.active {
      background: linear-gradient(90deg, #4f8cff22 30%, #a259ff22 100%);
      color: #4f8cff;
    }

    .menu-toggle {
      display: none;
      background: none;
      border: none;
      color: var(--text-color);
      font-size: 1.5rem;
      cursor: pointer;
      padding: 0.5rem;
      z-index: 1001;
    }

    .overlay {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0, 0, 0, 0.5);
      z-index: 999;
    }

    .overlay.active {
      display: block;
    }

    @media (max-width: 1024px) {
      .menu-toggle {
        display: block;
        position: fixed;
        top: 1rem;
        left: 1rem;
      }

      .nav-menu {
        display: none;
      }

      #theme-toggle {
        position: fixed;
        top: 1rem;
        right: 1rem;
      }
    }
  </style>
</head>

<body>
  <button class="menu-toggle" aria-label="Toggle menu">â˜°</button>
  <div class="overlay"></div>
  <div class="sidebar">
    <nav class="sidebar-nav">
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="predict.html">Predict</a></li>
        <li><a href="analyze.html">Analyze</a></li>
        <li><a href="train_results.html" class="active">Models & Results</a></li>
        <li><a href="about.html">About</a></li>
      </ul>
    </nav>
  </div>

  <header>
    <div class="header-container">
      <div class="logo">
        <a href="index.html"><img src="static/assets/logo.svg" alt="Logo" width="32" height="32">
          <span>StudentDepression</span></a>
      </div>
      <nav class="nav-menu">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="predict.html">Predict</a></li>
          <li><a href="analyze.html">Analyze</a></li>
          <li><a href="train_results.html" class="active">Models & Results</a></li>
          <li><a href="about.html">About</a></li>
        </ul>
      </nav>
      <button id="theme-toggle" aria-label="Toggle theme">
        <img src="static/assets/sun.svg" class="sun-icon" alt="Light mode" />
        <img src="static/assets/moon.svg" class="moon-icon" alt="Dark mode" />
      </button>
    </div>
  </header>

  <main class="analyze">
    <section>
      <h1>Model Training & Evaluation</h1>
      <p class="subtitle">
        Performance Analysis of Depression Prediction Models
      </p>

      <section class="train-section">
        <h2 id="model-training">Model Training</h2>
        <div class="model-report">
          <h3>Selected Models</h3>
          <ul class="model-list">
            <li>
              <strong>Logistic Regression:</strong> A fundamental and interpretable linear model, well-suited for binary
              classification tasks and offering strong baseline performance.
            </li>
            <li>
              <strong>K-Nearest Neighbors (KNN):</strong> A simple yet effective non-parametric model that makes no
              assumptions about data distribution, ideal for smaller to medium datasets.
            </li>
            <li>
              <strong>Random Forest:</strong> A powerful ensemble method that reduces overfitting and captures feature
              importance, providing robust predictions on complex datasets.
            </li>
            <li>
              <strong>Support Vector Machine (SVM):</strong> Highly effective in handling well-separated classes, with
              flexibility to manage non-linear patterns through kernel functions.
            </li>
          </ul>

          <h4>Reasons for Selection</h4>
          <ul class="reasons-list">
            <li>
              To ensure a diverse set of models for performance comparison across different algorithmic approaches.
            </li>
            <li>
              To include both <strong>simple models</strong> (Logistic Regression, KNN) and <strong>complex
                models</strong> (Random Forest, SVM) for a balanced evaluation.
            </li>
            <li>
              To match the characteristics of the dataset, which contains multiple features and a large number of
              samples, requiring both interpretability and scalability.
            </li>
          </ul>

          <style>
            .model-list li,
            .reasons-list li {
              margin-bottom: 1rem;
              line-height: 1.6;
            }
          </style>
        </div>
      </section>

      <section class="results-section">
        <h2 id="results-evaluation">Results & Evaluation</h2>
        <p class="subtitle">Model Performance Analysis</p>

        <div class="model-report">
          <h3 id="logistic-regression">Logistic Regression</h3>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/models/logreg_sklearn.png" alt="Logistic Regression (sklearn)" />
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/models/logreg_scratch.png" alt="Logistic Regression (scratch)" />
            </div>

          </div>
          <h4>ROC Curve Analysis</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/roc_curve/logreg_sklearn.png"
                alt="ROC Curve Logistic Regression (sklearn)" />
              <p class="chart-analysis">
                The ROC curve shows excellent model performance with an AUC of 0.92, indicating strong classification
                ability.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/roc_curve/logreg_scratch.png"
                alt="ROC Curve Logistic Regression (scratch)" />
              <p class="chart-analysis">
                The custom implementation achieves the same AUC of 0.92, proving its correctness and effectiveness.
              </p>
            </div>
          </div>
          <h4>Confusion Matrix</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/logreg_sklearn.png"
                alt="Confusion Matrix Logistic Regression (sklearn)" />
              <p class="chart-analysis">
                The model accurately predicts most cases, with 2916 true positives and 1819 true negatives.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/logreg_scratch.png"
                alt="Confusion Matrix Logistic Regression (scratch)" />
              <p class="chart-analysis">
                The results are nearly identical to the Scikit-learn version, with only minor differences in prediction
                counts. This further supports that the scratch implementation is functionally equivalent and reliable.
              </p>
            </div>
          </div>
        </div>

        <div class="model-report">
          <h3 id="knn">K-Nearest Neighbors (KNN)</h3>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/models/knn_sklearn.png" alt="KNN (sklearn)" />
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/models/knn_scratch.png" alt="KNN (scratch)" />
            </div>
          </div>
          <h4>ROC Curve Analysis</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/roc_curve/knn_sklearn.png" alt="ROC Curve KNN (sklearn)" />
              <p class="chart-analysis">
                The KNN model with Scikit-learn performs well, achieving an AUC of 0.89 with a strongly curved ROC.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/roc_curve/knn_scratch.png" alt="ROC Curve KNN (scratch)" />
              <p class="chart-analysis">
                The scratch version replicates the same AUC of 0.89, indicating it was correctly and efficiently
                implemented.
              </p>
            </div>
          </div>
          <h4>Confusion Matrix</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/knn_sklearn.png" alt="Confusion Matrix KNN (sklearn)" />
              <p class="chart-analysis">
                The model predicts 2911 true positives and 1679 true negatives, but has slightly more false positives.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/knn_scratch.png" alt="Confusion Matrix KNN (scratch)" />
              <p class="chart-analysis">
                This version has 2970 true positives and fewer false negatives, showing slightly better recall
                performance.
              </p>
            </div>
          </div>
        </div>

        <div class="model-report">
          <h3 id="random-forest">Random Forest</h3>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/models/rf_sklearn.png" alt="Random Forest (sklearn)" />
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/models/rf_scratch.png" alt="Random Forest (scratch)" />
            </div>
          </div>
          <h4>ROC Curve Analysis</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/roc_curve/rf_sklearn.png" alt="ROC Curve Random Forest (sklearn)" />
              <p class="chart-analysis">
                The Scikit-learn Random Forest model performs excellently with an AUC of 0.92, showing strong
                classification capability.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/roc_curve/rf_scratch.png" alt="ROC Curve Random Forest (scratch)" />
              <p class="chart-analysis">
                The scratch version achieves the same AUC of 0.92, confirming that the ensemble logic was implemented
                successfully.
              </p>
            </div>
          </div>
          <h4>Confusion Matrix</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/rf_sklearn.png"
                alt="Confusion Matrix Random Forest (sklearn)" />
              <p class="chart-analysis">
                The confusion matrix shows good balance between classes with slightly higher recall for positive cases
                (0.88) than negative cases (0.79), providing reliable predictions.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/rf_scratch.png"
                alt="Confusion Matrix Random Forest (scratch)" />
              <p class="chart-analysis">
                Similar class balance to the scikit-learn version, with marginally lower recall for negative cases
                (0.78), validating our tree ensemble implementation's effectiveness.
              </p>
            </div>
          </div>
        </div>

        <div class="model-report">
          <h3 id="svm">Support Vector Machine (SVM)</h3>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/models/svm_sklearn.png" alt="SVM (sklearn)" />
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/models/svm_scratch.png" alt="SVM (scratch)" />
            </div>
          </div>
          <h4>ROC Curve Analysis</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/roc_curve/svm_sklearn.png" alt="ROC Curve SVM (sklearn)" />
              <p class="chart-analysis">
                The Scikit-learn SVM model performs strongly with an AUC of 0.92, indicating excellent discriminative
                power.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/roc_curve/svm_scratch.png" alt="ROC Curve SVM (scratch)" />
              <p class="chart-analysis">
                The scratch SVM implementation achieves the same AUC of 0.92, showing successful replication of the
                kernel logic.
              </p>
            </div>
          </div>
          <h4>Confusion Matrix</h4>
          <div class="visualization-group">
            <div>
              <h5>Scikit-learn Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/svm_sklearn.png" alt="Confusion Matrix SVM (sklearn)" />
              <p class="chart-analysis">
                SVM balances well between classes with similar recall rates for both positive (0.88) and negative (0.80)
                cases, making it suitable for general classification tasks.
              </p>
            </div>
            <div>
              <h5>Scratch Implementation</h5>
              <img src="static/dataset/results/confusion_matrix/svm_scratch.png" alt="Confusion Matrix SVM (scratch)" />
              <p class="chart-analysis">
                Our implementation shows slightly better performance on negative cases (0.82 recall) with marginally
                lower positive recall (0.87), a promising result for a custom implementation.
              </p>
            </div>
          </div>
        </div>

        <div class="model-report">
          <h3 id="model-comparison">Model Comparison</h3>

          <div class="model-comparison-table">
            <table>
              <thead>
                <tr>
                  <th>Model</th>
                  <th>Precision</th>
                  <th>Recall</th>
                  <th>F1-Score</th>
                  <th>Accuracy</th>
                  <th>AUC</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Logistic Regression (Scikit-learn)</td>
                  <td>0.8666</td>
                  <td>0.8834</td>
                  <td>0.8749</td>
                  <td>0.8502</td>
                  <td><strong>0.92</strong></td>
                </tr>
                <tr>
                  <td>Logistic Regression (Scratch)</td>
                  <td>0.8682</td>
                  <td>0.8843</td>
                  <td><strong>0.8762</strong></td>
                  <td><strong>0.8519</strong></td>
                  <td><strong>0.92</strong></td>
                </tr>
                <tr>
                  <td>KNN (Scikit-learn)</td>
                  <td>0.8317</td>
                  <td>0.8819</td>
                  <td>0.8561</td>
                  <td>0.8242</td>
                  <td>0.89</td>
                </tr>
                <tr>
                  <td>KNN (Scratch)</td>
                  <td>0.8195</td>
                  <td><strong>0.8997</strong></td>
                  <td>0.8578</td>
                  <td>0.8231</td>
                  <td>0.89</td>
                </tr>
                <tr>
                  <td>Random Forest (Scikit-learn)</td>
                  <td>0.8604</td>
                  <td>0.8791</td>
                  <td>0.8696</td>
                  <td>0.8438</td>
                  <td><strong>0.92</strong></td>
                </tr>
                <tr>
                  <td>Random Forest (Scratch)</td>
                  <td>0.8552</td>
                  <td>0.8697</td>
                  <td>0.8624</td>
                  <td>0.8355</td>
                  <td><strong>0.92</strong></td>
                </tr>
                <tr>
                  <td>SVM (Scikit-learn)</td>
                  <td>0.8660</td>
                  <td>0.8846</td>
                  <td>0.8752</td>
                  <td>0.8504</td>
                  <td><strong>0.92</strong></td>
                </tr>
                <tr>
                  <td>SVM (Scratch)</td>
                  <td><strong>0.8751</strong></td>
                  <td>0.8679</td>
                  <td>0.8715</td>
                  <td>0.8483</td>
                  <td><strong>0.92</strong></td>
                </tr>
              </tbody>
            </table>
          </div>

          <style>
            .model-comparison-table {
              margin: 2rem 0;
              overflow-x: auto;
            }

            .model-comparison-table table {
              width: 100%;
              border-collapse: collapse;
              text-align: center;
            }

            .model-comparison-table th {
              background-color: rgba(82, 82, 82, 0.226);
              padding: 0.8rem;
              border: 1px solid rgba(128, 128, 128, 0.2);
            }

            .model-comparison-table td {
              padding: 0.8rem;
              border: 1px solid rgba(128, 128, 128, 0.2);
            }

            .model-comparison-table tr:nth-child(even) {
              background-color: rgba(128, 128, 128, 0.05);
            }

            .model-comparison-table tr:hover {
              background-color: rgba(128, 128, 128, 0.1);
            }
          </style>

          <p class="comparison-summary">From the comparison table, all models demonstrate strong classification
            performance, but notable differences appear when evaluating across Precision, Recall, F1-score, Accuracy,
            and AUC:</p>
          <ul class="model-analysis">
            <li>
              <strong>Logistic Regression (Scratch)</strong> slightly outperforms its Scikit-learn counterpart in all
              four metrics (F1-score: <strong>0.8762</strong>, Accuracy: <strong>0.8519</strong>), making it the
              top-performing model overall.
            </li>
            <li>
              <strong>Support Vector Machine (Scikit-learn)</strong> also performs exceptionally well, achieving the
              highest Accuracy (<strong>0.8504</strong>) among Scikit-learn models, and a strong F1-score of 0.8752.
            </li>
            <li>
              <strong>KNN (Scratch)</strong> yields the <strong>highest Recall (0.8997)</strong> among all models, which
              is beneficial when identifying as many positive (depressed) cases as possible, though its precision and
              accuracy are slightly lower.
            </li>
            <li>
              <strong>Random Forest (Scikit-learn)</strong> offers a balanced trade-off across all metrics (F1-score:
              0.8696, Accuracy: 0.8438) and maintains a strong AUC of 0.92, confirming robust performance.
            </li>
            <li>
              <strong>SVM (Scratch)</strong> achieves the <strong>highest Precision (0.8751)</strong>, making it
              excellent for applications where false positives are particularly costly.
            </li>
            <li>
              All models except KNN achieve an AUC of <strong>0.92</strong>, showing consistent discriminative power,
              while <strong>KNN models</strong> have slightly lower AUC (0.89), indicating modestly weaker boundary
              definition.
            </li>
          </ul>

          <p class="comparison-conclusion">In conclusion, <strong>Logistic Regression (Scratch)</strong> and <strong>SVM
              (Scikit-learn)</strong> emerge as the most reliable models in this context, with strong generalization and
            high classification metrics, while <strong>KNN (Scratch)</strong> stands out for maximum sensitivity.</p>

          <style>
            .comparison-summary {
              margin-top: 1.5rem;
              font-size: 1.05rem;
              line-height: 1.6;
            }

            .model-analysis {
              margin: 1.5rem 0;
              padding-left: 1.2rem;
            }

            .model-analysis li {
              margin-bottom: 1rem;
              line-height: 1.6;
            }

            .comparison-conclusion {
              margin-top: 1.5rem;
              font-size: 1.05rem;
              font-weight: 500;
              line-height: 1.6;
              padding: 1rem;
              border-left: 4px solid var(--accent-color);
              background: rgba(128, 128, 128, 0.05);
            }
          </style>
        </div>
      </section>
    </section>
    <aside class="content-summary">
      <h4>On this page</h4>
      <ul>
        <li><a href="#model-training">Model Training</a></li>
        <li>
          <a href="#results-evaluation">Results & Evaluation</a>
          <ul>
            <li><a href="#logistic-regression">Logistic Regression</a></li>
            <li><a href="#knn">K-Nearest Neighbors (KNN)</a></li>
            <li><a href="#random-forest">Random Forest</a></li>
            <li><a href="#svm">Support Vector Machine (SVM)</a></li>
            <li><a href="#model-comparison">Model Comparison</a></li>
          </ul>
        </li>
      </ul>
    </aside>
  </main>
  <script src="js/script.js"></script>
</body>

</html>